# TALLER_JSL2024
## 1. Introducci√≥n al an√°lisis de datos lidar con R, y modelizaci√≥n 3d con Blender.

El motivo que persigue este breve taller introductorio, es mostrar un flujo de trabajo elemental, para el procesado de datos LiDAR desde el entorno de R. El objetivo ser√° generar un modelo digital del terreno y un modelo digital de superficie que posteriormente, se podr√° visualizar en forma de escenario tridimensional, utilizando para ello el programa de dise√±o 3d **Blender**.

## 2. Software necesario para el desarrollo del taller:

* **[R](https://www.r-project.org/)** y **[Rstudio](https://posit.co/download/rstudio-desktop/)**
* **[QGIS](https://qgis.org/en/site/)**
* **[Blender](https://www.blender.org/)**

## 3. Datos que se utilizar√°n en el taller:

B√°sicamente se van a utilizar datos LiDAR, que pueden descargarse de cualquier geoportal de datos abiertos tales como el visor de descargas del **[ICGC](http://www.icc.cat/appdownloads/)** o el Centro de Descargas del **[CNIG](https://centrodedescargas.cnig.es/CentroDescargas/index.jsp)**, entre otros.

Para el presente taller pod√©is, descargar los datos desde aqu√≠ (fuente de los datos: ICGC):

* [1 fichero LAZ](https://drive.google.com/file/d/11XUt-XEteQU_O-_m4G38X1BKu6lyam8W/view?usp=sharing)
* [conjunto de ficheros LAZ](https://drive.google.com/file/d/161cLiO64T_0-hW5k2JQh1QBFw-gw9FmO/view?usp=sharing)

## 4. Trabajando con datos LiDAR desde R
### 4.1. Configurar el espacio de trabajo

R se trabajar√° desde el entorno de desarrollo RStudio, que facilita sobremanera la gesti√≥n de ficheros, _scripts_, carpetas, proyectos y datos, as√≠ como la propia visualizaci√≥n de los mapas, capas o gr√°ficos. As√≠ pues, abriremos RStudio y empezaremos por configurar el entorno de trabajo, bien indicando cual es el **directorio de trabajo** -_setwd()_- o bien, configurando un proyecto desde cero (_.Rproj_). Tambi√©n necesitaremos crear un _script_ de R.

```R
setwd("ruta/de/acceso/a/los/datos")   # establecer la ruta al directorio de trabajo
getwd()   # comprobar la ruta al directorio de trabajo
```

A continuaci√≥n, se instalar√° y activar√° el paquete con el cual se va a trabajar: **lidR**

```R
install.packages("lidR)   # instalaci√≥n del paquete lidR
library(lidR)   # llamada del paquete lidR
```

### 4.2. Lectura y comprobaciones b√°sicas sobre los ficheros LAS/LAZ
#### 4.2.1. Lectura de un fichero LAS/LAZ

Una vez configurado el punto de partida, el siguiente paso consiste en la lectura del fichero o ficheros LAS/LAZ, y la creaci√≥n del correspondiente objeto de R que contendr√° toda la informaci√≥n. La funci√≥n del paquete **lidR** que permite la lectura de ficheros LiDAR, es **_readLAS()_**. Como todas las funciones de R, √©sta se compone de varios argumentos posibles que pueden configurarse o no, en funci√≥n de la informaci√≥n que precisemos extraer de los ficheros originales:

```R
# importar 1 fichero las/laz: opci√≥n b√°sica
las1 <- readLAS("datos_lidar/1_fichero_laz/LIDARCATv02ls12f360716ed02.laz")

# recuperar informaci√≥n b√°sica del objeto reci√©n creado:
print(las1)   # informaci√≥n b√°sica
summary(las1)   # informaci√≥n extendida

# comprobar el sistema de referencia de coordenadas
crs(las1)
epsg(las1)
```
En el caso anterior, la funci√≥n **_readLAS()_** lee la totalidad del archivo original, y traspasa dicha informaci√≥n al nuevo objeto de R (perteneciente a la clase **LAS**). En ocasiones pero, puede interesar √∫nicamente extraer algunos de los atributos que contiene el fichero LiDAR (valores XYZ, intensidad, clasificaci√≥n, ...)

![Atributos de un fichero LAS](/image/atributos_las.png)

#### 4.2.2. Importar parte del fichero (I). La selecci√≥n de atributos: SELECT

Uno de los argumentos que soporta la funci√≥n b√°sica **_readLAS()_**, es la selecci√≥n de los atributos que se quieren leer/importar. El argumento en cuesti√≥n lleva por nombre, ```select```. As√≠ por ejemplo, puede crearse un nuevo objeto que contenga √∫nicamente, parte los atributos originales:

```r
# seleccionar los atributos a leer/importar
las_xyz <- readLAS("datos_lidar/1_fichero_laz/LIDARCATv02ls12f360716ed02.laz", select = "xyz")   # xyz
las_clasificado <- readLAS("datos_lidar/1_fichero_laz/LIDARCATv02ls12f360716ed02.laz", select = "xyzc")   # xyz y clasificaci√≥n
```
L√≥gicamente, la cantidad de atributos que se leen/importan en R afectar√°:

* al tama√±o del objeto,
* y a la cantidad de informaci√≥n disponible y, por consiguiente, lo que podamos hacer con este objeto.

![Tama√±o del objeto LAS](/image/peso_las.png)

En los ejemplos anteriores se han importado las coordenadas XY y el valor de Z en el primer caso (xyz), y se ha a√±adido el atributo de clasificaci√≥n en el segundo (c). A continuaci√≥n, se muestran algunas de las abreviaciones del resto de atributos posibles:

| Abreviaci√≥n | Atributo               |
|-------------|------------------------|
| t           | hora del gps           |
| a           | √°ngulo de escaneo      |
| i           | intensidad             |
| n           | n√∫mero de retornos     |
| r           | n√∫mero de retorno      |
| c           | clasificaci√≥n          |
| p           | identificador de punto |
| ...         | ...                    |

#### 4.2.3. Importar parte del fichero (II). La selecci√≥n de puntos: FILTER

Adem√°s de escoger qu√© atributos se van a leer, tambi√©n es posible seleccionar √∫nicamente una parte de las geometr√≠as que conforman la nube de puntos LiDAR. Para ello, se utilizar√° el argumento ```filter``` dentro de la funci√≥n **_readLAS()_**.

```r
# seleccionar los puntos a importar, en base a sus caracter√≠sticas:
las_xyz_fr <- readLAS("datos_lidar/1_fichero_laz/LIDARCATv02ls12f360716ed02.laz",
                   select = "xyz",
                   filter = "-keep_first")   # xyz y primer rebote

las_xyz_ground <- readLAS("datos_lidar/1_fichero_laz/LIDARCATv02ls12f360716ed02.laz",
                      select = "xyz",
                      filter = "-keep_class 2")   # xyz y clasificado como suelo

las_xyz_1k_2k <- readLAS("datos_lidar/1_fichero_laz/LIDARCATv02ls12f360716ed02.laz",
                          select = "xyz",
                          filter = "-keep_z 1000 2000")   # xyz comprendidos entre 1000 y 2000 metros
```
Para comprobar las caracter√≠sticas de cada uno de los objetos generados, basta con ejecutar las funciones **_print()_** para obtener una versi√≥n simplificada, o **_summary()_** para obtener m√°s detalles. Con relaci√≥n a la clasificaci√≥n presente en una nube de puntos LiDAR, la referencia es la especificaci√≥n de la ASPRS (_The American Society for Photogrammetry & Remote Sensing_):

![Clasificaci√≥n de puntos lidar](/image/las_classes.png)

Para consultar todas las posibilidades que admite el argumento ```filter```, basta con ejecutar la siguiente funci√≥n:

```r
readLAS(filter = "-help")
```

#### 4.2.4. Validar los objetos creados con la funci√≥n readLAS()

La validaci√≥n de los objetos creados con la funci√≥n readLAS() o dicho de otro modo, la confirmaci√≥n que los datos son v√°lidos para su procesamiento y para generar, por ejemplo, un modelo digital del terreno, pasa por comprobar si estos objetos o datos se ajustan a las especificaciones emitidas por la ASPRS. La funci√≥n encargada de dicha validaci√≥n es **_las_check()_:**

```r
las_check(las1)
las_check(las_xyz_ground)
```
Uno de los problemas que, de manera frecuente, afectan o pueden afectar a los datos LiDAR es la presencia de puntos duplicados. La funci√≥n **_las_check()_** informa de la presencia de estos puntos, lo que permite que puedan ser eliminados del objeto con el cual se va a trabajar.

```r
Checking the data
  - Checking coordinates... ‚úì
  - Checking coordinates type... ‚úì
  - Checking coordinates range... ‚úì
  - Checking coordinates quantization... ‚úì
  - Checking attributes type... ‚úì
  - Checking ReturnNumber validity... ‚úì
  - Checking NumberOfReturns validity... ‚úì
  - Checking ReturnNumber vs. NumberOfReturns... ‚úì
  - Checking RGB validity... ‚úì
  - Checking absence of NAs... ‚úì
  - Checking duplicated points...
    ‚ö† 1943 points are duplicated and share XYZ coordinates with other points
  - Checking degenerated ground points... ‚úì
```
Adem√°s, durante el proceso de validaci√≥n se informa tambi√©n de la presencia o no de puntos etiquetados como ```withheld```. Estos, son puntos que se han etiquetado de este modo porqu√© no son confiables, y no deber√≠an ser tomados en cuenta para ning√∫n tipo de an√°lisis:

```r
  - Checking degenerated ground points... ‚úì
  - Checking attribute population... ‚úì
  - Checking gpstime incoherances ‚úì
  - Checking flag attributes...
    üõà 1496514 points flagged 'withheld'
  - Checking user data attribute... ‚úì
```
Por lo general, se tata de puntos que son considerados errores o ruido. Frente a la presencia de este tipo de puntos etiquetados como 'withheld', pueden adoptarse varias estrategias:

* Filtrar los puntos etiquetados como 'withheld' del objeto, antes de proceder a generar productos derivados.
* En algunos casos, si no se tata de una gran cantidad de puntos, cabe la posibilidad de valorar si parte de estos pueden integrarse en futuros an√°lisis o no.
* Y si la cantidad de puntos no confiables es muy alta, convendria adem√°s de no tomarlos en cuenta, investigar su origen y notificar esta cuesti√≥n al proveedor de los datos.

En cualquier caso, para empezar conviene solucionar el primer error o aviso que lanza la funci√≥n **_las_check()_**: la presencia de **puntos duplicados**.

#### 4.2.5. Eliminar los puntos duplicados en un objeto LAS

Para eliminar los puntos que est√°n duplicados en una nube de puntos, basta con utilizar la funci√≥n _**filter_duplicates()**_. El nuevo objeto que se va a generar, va a estar libre de estos duplicados. Esta situaci√≥n puede comprobarse utilizando la funci√≥n de validaci√≥n de datos.

```r
las1_nodup <- filter_duplicates(las1)   # eliminaci√≥n de puntos duplicados
las_check(las1_nodup)   # validaci√≥n del nuevo objeto
```
En el resultado que muestra la consola, se aprecia que los 1943 puntos duplicados ya no est√°n presentes en el nuevo objeto:

```
  - Checking RGB validity... ‚úì
  - Checking absence of NAs... ‚úì
  - Checking duplicated points... ‚úì
  - Checking degenerated ground points... ‚úì
  - Checking attribute population... ‚úì
  - Checking gpstime incoherances ‚úì
  - Checking flag attributes...
    üõà 1494805 points flagged 'withheld'
  - Checking user data attribute... ‚úì
```

#### 4.2.6. Eliminar los puntos etiquetados como 'withheld'

En el contexto de este taller, para deshacernos de estos puntos no confiables, puede utilizarse una doble v√≠a:

* o bien se utiliza una funci√≥n especifica para el filtrado de puntos,
* o bien se genera de nuevo un objeto LAS con **_readLAS()_**, pero esta vez, utilizando el argumento ```filter``` para desechar estos puntos desde un buen inicio:

```r
# crear nuevamente el objeto LAS, aplicando un filtro durante su lectura
las1_nowithheld <- readLAS("datos_lidar/1_fichero_laz/LIDARCATv02ls12f360716ed02.laz", filter = "-drop_withheld")   # lectura
print(las1_nowithheld)   # resumen
las_check(las1_nowithheld)   # validaci√≥n

# filtrar el objeto anteriormente creado, que contiene los puntos etiquetados como ruido
las1_filtrado <- filter_poi(las1_nodup, Classification != 7)   # filtrado
print(las1_filtrado)   # resumen
las_check(las1_filtrado)   # validaci√≥n
```

Sea cual sea el m√©todo aplicado, se acabar√° por llegar al mismo punto:

```
> print(las1_filtrado)   # resumen
class        : LAS (v1.2 format 1)
memory       : 595.2 Mb 
extent       : 360000, 362000, 4716000, 4718000 (xmin, xmax, ymin, ymax)
coord. ref.  : ETRS89 / UTM zone 31N 
area         : 3.98 km¬≤
points       : 9.18 million points
density      : 2.31 points/m¬≤
density      : 1.97 pulses/m¬≤
> print(las1_nowithheld)   # resumen
class        : LAS (v1.2 format 1)
memory       : 560.2 Mb 
extent       : 360000, 362000, 4716000, 4718000 (xmin, xmax, ymin, ymax)
coord. ref.  : ETRS89 / UTM zone 31N 
area         : 3.98 km¬≤
points       : 9.18 million points
density      : 2.31 points/m¬≤
density      : 1.97 pulses/m¬≤
```
**Nota**: no siempre ambos sistemas, pueden aplicarse indistintamente:

```r
# error!
las_xyz <- readLAS("datos_lidar/1_fichero_laz/LIDARCATv02ls12f360716ed02.laz", select = "xyz")   # lectura
# Warning message:
# There are 1496514 points flagged 'withheld'.

las1_nowithheld <- filter_poi(las_xyz, Classification != 7)   # filtrado con error!
# Error in eval(expr, data, expr_env) : object 'Classification' not found
```
La cantidad de atributos que se importen inicialmente para la creaci√≥n de un objeto de la clase LAS, puede determinar en cierto modo, las funciones que vayamos a poder aplicar posteriormente.

### 4.3. Generar productos derivados del objeto LAS
#### 4.3.1. Modelos digitales del terreno

Por defecto, el algoritmo **_rasterize_terrain()_** utiliza, para la generaci√≥n de un modelo digital del terreno, √∫nicamente aquellos puntos que est√©n clasificados como suelo (2) y agua (9). As√≠ pues bastar√° con definir la resoluci√≥n del modelo, y el algoritmo de interpolaci√≥n a utilizar, sin necesidad de aplicar pr√©viamente la funci√≥n **_filter_poi()_** en conjunci√≥n con el argumento ```Classification``` para seleccionar los puntos de inter√©s:

```r
suelo <- filter_poi(las1_filtrado, Classification == c(2,9))
```
A continuaci√≥n se muestran tres procesos de interpolaci√≥n para generar una superficie continua de valores:

##### a) Red de triangulos irregulares (TIN)

```r
# TIN
dtm_tin <- rasterize_terrain(las1_filtrado, res = 1, algorithm = tin())   # interpolaci√≥n
lidR::plot(dtm_tin)   # representaci√≥n 2D
lidR::plot_dtm3d(dtm = dtm_tin)   # representaci√≥n 3D
```
##### b) Distancia Inversa Ponderada (IDW)

```r
# IDW
mdt_idw <- rasterize_terrain(las1_filtrado , algorithm = knnidw(k = 10L, p = 2))  # interpolaci√≥n
lidR::plot(mdt_idw)   #representaci√≥n 2D
lidR::plot_dtm3d(mdt_idw, bg = "black")   #representaci√≥n 3D 
```

##### c) Kriging

```r
# Kriging
mdt_kriging <- rasterize_terrain(las, algorithm = kriging(k = 40))   # interpolaci√≥n
lidR::plot(mdt_kriging)   # representaci√≥n 2D
lidR::plot_dtm3d(mdt_kriging, bg = "black")   # representaci√≥n 3D
```

![TIN](/image/tin.png)

#### 4.3.2.Modelos digitales de superficie
A diferencia de la funci√≥n anterior, **_rasterize_canopy()_** utilizar√° el primer rebote almacenado para generar un modelo digital de superficie. Y del mismo modo que suced√≠a en el caso de la funci√≥n **_rasterize_terrain()_**, en esta ocasi√≥n tambi√©n disponemos de varios algoritmos para llevar a cabo la interpolaci√≥n: **p2r()**, **dsmtin()**, **pitfree()**.  

##### Red de triangulos irregulares (TIN)
```r
# MDS TIN
mds_tin <- rasterize_canopy(las1_nowithheld , res = 0.5, algorithm = dsmtin())
lidR::plot(mds_tin)
lidR::plot_dtm3d(mds_tin)
```
##### Algoritmo PITFREE
```r
# MDS PITFREE
mds_pitfree <- rasterize_canopy(las1_nowithheld, res = 0.5, algorithm = pitfree())
lidR::plot(mds_pitfree)
lidR::plot_dtm3d(mds_pitfree)
```
##### Algoritmo p2r
```r
# MDS p2r
mds_pitfree <- rasterize_canopy(las1_nowithheld, res = 0.5, algorithm = pitfree())
lidR::plot(mds_pitfree)
lidR::plot_dtm3d(mds_pitfree)
```

![DSM2](/image/dsm2.png)

## 5. Visualizaciones 3D en R

Adem√°s de la funci√≥n **_plot_dtm3()_** propia del paquete lidR, existen en R otras opciones para visualizar datos en 3D, como por ejemplo utilizando el paquete **rayshader**.

### 5.1. Trabajando con el paquete rayshader
Como siempre en R, en caso que sea necesario, hay que instalar y llamar el paquete **rayshader**,:

```r
install.packages("rayshader")
library(rayshader)
```

A continuaci√≥n, ser√° preciso convertir el objeto raster (perteneciente a la clase SpatRaster) en una matriz, con ayuda de la funci√≥n **_raster_to_matrix()_**:
```r
matriz_mds <- raster_to_matrix(mds_tin)
```

Y a continuaci√≥n, aplicar una textura a la matriz, y visualizarla en un plot 2D:

```r
# aplicar textura a la matriz, y visualizar en 2D
matriz_mds |>   
  sphere_shade(texture = "desert") |> 
  plot_map()

# podemos a√±adir una capa o layer de iluminaci√≥n/sombras
matriz_mds |> 
   sphere_shade(texture = "desert") |> 
   add_shadow(ray_shade(matriz_mds), 0.5) |> 
   plot_map()

# y generar un escenario 3D
matriz_mds |> 
   sphere_shade(texture = "desert") |> 
   add_shadow(ray_shade(matriz_mds, zscale = 3), 0.5) |> 
   add_shadow(ambient_shade(matriz_mds), 0) |> 
   plot_3d(matriz_mds, zscale = 10, fov = 0, theta = 135, zoom = 0.75, phi = 45, windowsize = c(1000, 800))
```

## 6. Trabajando con varias hojas LiDAR

Hasta el momento, se ha visto c√≥mo trabajar con una sola hoja de datos LiDAR. De todos modos, lo normal es trabajar con extensiones de terreno superiores a lo abarca una √∫nica hoja de datos LiDAR, por lo que en ocasiones ser√° necesario trabajar varias hojas a la vez. En estos castos, se va a trabajar con otro tipo de objeto del paquete lidR: un objeto de la clase **LAScatalog**.

Para empezar, se deben leer todos los ficheros LiDAR contenidos en una carpeta, y generar el objeto con el cual se va a trabajar:

```r
library(lidR)
library(terra)

setwd("/ruta/a/carpeta/de/datos_lidar/")

# creaci√≥n de un cat√°logo
lasCat <- readLAScatalog("hojas_laz/", filter = "-drop_withheld")

class(lasCat)
lasCat   # ver caracter√≠sticas del cat√°logo
plot(lasCat)   # visualizamos la disposici√≥n de hojas LiDAR

las_check(lasCat)   # validaci√≥n del cat√°logo
```
Una vez agrupadas todas las hojas LiDAR en un objeto de tipo **LAScatalog**, ser√° el momento de definir los fragmentos, o teselas en las que se dividir√° el cat√°logo generado. Cierto es que se puede procesar el cat√°logo hoja a hoja, siguiendo la extensi√≥n de las hojas originales, o bien con ayuda de las funciones **_opt_chunk_size()_** y **_opt_chunk_buffer()_**, definir un nuevo tama√±o de tesela y la zona de solape entre las distintas hojas, a fin de evitar las posibles y temidas l√≠neas de separaci√≥n entre hojas.

```r
# definici√≥n del tama√±o de las hojas o teselas, y el solape
opt_chunk_size(lasCat) <- 1000
opt_chunk_buffer(lasCat) <- 50

# y visualizamos la nueva disposici√≥n de hojas
plot(lasCat, chunk_pattern = TRUE)
```
A continuaci√≥n, se puede procesar el objeto **lasCat**, para generar un modelo digital del terreno utilizando para ello el algoritmo **_tin()_**

```r
# generaci√≥n del modelo digital de elevaciones
lasCat_class <- rasterize_terrain(lasCat, res = 1,algorithm = tin())

plot(lasCat_class)   # gr√°fico 2D
plot_dtm3d(lasCat_class)   # gr√°fico 3D
```
## 7. Visualizaciones 3D en Blender

### 7.1. La preparaci√≥n de los datos
Antes de pasar a trabajar con Blender para recrear un escenario 3D, deben prepararse los datos a fin de aprovechar al m√°ximo, las capacidades de Blender para el modelado del relieve. Ello implicar√° guardar el modelo digital del terreno o de elevaciones, como una imagen de valores enteros de 16 bits sin signo (UInt16). El prop√≥sito es obtener una nueva imagen con valores comprendidos entre 0 y 65535. Esta transformaci√≥n, puede hacerse des de QGIS, utilizando la calculadora raster, o bien desde R. Para realizar dicha transformaci√≥n hay que aplicar la f√≥rmula "**_(valor del raster - valor m√≠nimo) / (valor m√°ximo - valor m√≠nimo) * 65535_**":

En el _script_ de R, deber√°n a√±adirse las siguientes l√≠neas de c√≥digo:

```r
# obtener el m√≠nimo y m√°ximo de la imagen
library(terra)
min_val <- minmax(lasCat_class)[1]
max_val <- minmax(lasCat_class)[2]

# aplicar √°lgebra de mapas
mdtLasCat <- (lasCat_class - min_val) / (max_val - min_val) * 65535

# exportar objeto raster a capa raster
writeRaster(mdtLasCat, "/home/lluis/mdt_lasCat.tif", datatype = 'INT2U')
```
Ahora s√≠, es el turno de **Blender**.

### 7.2. La configuraci√≥n de Blender, paso a paso

#### 7.2.1. El espacio de trabajo
* Al abrir el programa, siempre aparecen en la ventana principal, tres elementos b√°sicos: un **cubo**, una fuente de **luz**, y una **c√°mara**. Se seleccionar√° el cubo, y se eliminar√° ya que en su lugar, se utilizar√° la imagen creada en el paso anterior.
* En el men√∫ Edit > Preferences, hay que activar la extensi√≥n o funci√≥n **Import Images as Planes**.

#### 7.2.2. La importaci√≥n del modelo digital de superficie o del terreno
* Antes de nada, se dividir√° el espacio de trabajo en un doble panel: el **3D Viewport** y el **Shader Editor**. Este √∫ltimo, se utilizar√° para configurar el escenario mientras que, en el primero, se ir√° visualizando una muestra del escenario que se est√° configurando.
* A continuaci√≥n, hay que importar el modelo digital (en formato de imagen) preparado anteriormente, como un nuevo objeto de tipo **plano** (_plane_). Para ello, basta con dirigirse al men√∫ File > Import > Images as Planes,  seleccionar el fichero **dsm_blender.tif**, y aceptar.
* El plano reci√©n importado, puede visualizarse de tres modos distintos: **s√≥lido**, **material** y **_rendered_**, pinchando sobre les tres iconos en forma de esfera visibles en el √°ngulo superior derecho de la ventana **3D Viewport**.
* En el apartado **Render**, hay que modificar el par√°metro **Render Engine** a **Cycles** y el **Feature Set**, configurarlo como **Experimental**.
* El siguiente paso, consistir√° en a√±adir al plano de trabajo, todos nodos que sean necesarios para poder **"deformar"** el plano y representar el relieve del modelo digital. Para ello, en el apartado **Modifiers**, hay que a√±adir un nuevo modificador (Add Modifier > Generate > Subdivision surface), activar el bot√≥n **Simple** y activar la casilla **Adaptative Subdivision**.
* De nuevo en el apartado **Render** para mejorar la velocidad de representaci√≥n durante la fase de dise√±o, se pueden modificar los valores presentes en el par√°metro Viewport > Max samples a **512**, y el valor del par√°metro Render > Max samples a **30**. Estos valores podr√°n modificarse segun sea conveniente en cada caso y situaci√≥n.
* Ahora, en la ventana del **Shader Editor**, se observan tres piezas distintas: el modelo digital (imagen), un algoritmo que configura c√≥mo se va a _renderizar_ el modelo, y el objeto de salida, conectados entre s√≠.

#### 7.2.3. Convertir el plano en un relieve
* Llegados a este punto, es el momento de aplicar las deformaciones al plano que contiene la imagen, en base a la interpretaci√≥n de la paleta de colores y de los valores del modelo digital de superficie.
* Se a√±ade un nuevo nodo desde el men√∫ Add > Vector > Displacement. Y se enlaza el conector **Color** de la imagen, al conector **Height** del m√≥dulo encargado de configurar el desplazamiento, y el conector **Displacement** de este √∫ltimo, al conector **Displacement** del nodo **Material Output**.

![blender1](/image/blender1.png)

* Al conmutar la vista de material a renderizado, aun no puede apreciarse el desplazamiento que ha sufrido el plano orginal. Para ello, en el apartado **Material > Settings**, deber√° modificarse el valor del par√°metro **Displacement** de la opci√≥n **Bump only** a la opci√≥n **Displacement only**. A continuaci√≥n, hay que ajustar el valor de exageraci√≥n en el par√°metro **Scale** del nodo **Displacement** hasta el valor que resulte m√°s apropiado.

#### 7.2.4. Configurar la iluminaci√≥n
* Para que el escenario vaya ganando en realismo y se a√±ada el correspondiente sombreado, hay que configurar el foco de luz que ilumina la escena.
* Hay que selecionar el objeto luz (**Light**) en el panel de objetos y, en el apartado de propiedades, se pueden configurar los par√°metros de localizaci√≥n, rotaci√≥n, o escalado, por ejemplo. Los valores de **Rotation** pueden configurarse del siguiente modo (x = 0, y = 45, z = 135). Estos valores tambi√©n pueden configurarse de manera manual, seleccionando y arrastrando el punto de luz visible en el escenario.
* A continuaci√≥n, hay que activar el apartado Data (bombilla de color verde), y escoger el sol, como fuente de luz, ajustar la potencia a 4.5, y el √°ngulo a **2**. 

#### 7.2.5. Configurar la c√°mara
* Este elemento es indispensable para poder _renderizar_ el escenario. Para comprobar que es lo que est√° observando la c√°mara (es decir, qu√© parte del escenario se va a _renderizar_ y desde que perspectiva), basta con presionar la tecla 0.
* Se puede configurar la vista del escenario de manera manual y a continuaci√≥n, activar el men√∫ View > Align View > Align Active Camera to View, y acabar de ajustar manualmente la perspectiva seleccionando la c√°mara en el panel de objetos y presionando la tecla **G**.
* Para ver una primera renderizaci√≥n del escenario, basta con presionar la tecla **F12**.
* Para configurar un plano zenita, basta con configurar la capa de **Perspective** a **Orthogonal**, presionar la tecla 7 para obtener uan visi√≥n desde arriba (top) y a continuaci√≥n, activar el men√∫ View > Align View > Align Active Camera to View. De nuevo en las propiedades de la c√°mara, se puede ajustar la vista con el par√°metro **Orthographic Scale**.

#### 7.2.6. A√±adir una paleta de paleta de colores
* Para llevar a cabo esta operaci√≥n, existen dos posibilidades (como m√≠nimo!): dise√±ar una paleta de colores en Blender, o bien hacer el trabajo en QGIS, por ejemplo.
* Con QGIS abierto, hay que cargar el modelo digital del terreno con el cual se est√° trabajando, y aplicar una paleta de colores predefinida como por ejemplo las que hay accesibles en el cat√°logo **cpt-city**. Una vez aplicada la paleta escogida al mdt, hay que exportar la capa(o capas), como una im√°genen 'renderizada', para que se guarde el estilo aplicado.
* De nuevo en Blender, dentro del panel del Shader Editor, se a√±adir√°n tantas texturas de imagen como paletas de color se hayan preparado. En cada nuevo nodo de textura de imagen se abrir√° una de las nuevas im√°genes generadas en QGIS, y deber√° conectarse al nodo **PrincipledBSDF** mediante el conector Color > Base color.
* Por lo que respecta a la c√°mara, antes de renderizar la nueva escena, si se quiere mantener una c√°mara zenital y a√±adir una nueva c√°mara de perspectiva, puede hacerse desde el men√∫ Add > Camera.
* Add > Converter > Color ramp

![escenario](/image/escenario0.png)

### 7.2.7 A√±adir una im√°gen a√©rea, y otros elementos sobre el relieve
* Del mismo modo que puede configurarse una paleta de colores, y aplicarla sobre el relieve, tambi√©n es posible aplicar otros elementos tales como fotograf√≠as a√©reas, im√°genes de sat√©lite, u otras capas que ejerzan de m√°scara como puede ser el caso de l√°minas de agua (r√≠os, lagos, mar, ...). Lo recomendable en estos casos, es configurar todas estas capas utilizando QGIS.
* El el caso particular de la fotograf√≠a a√©rea, pueden obtenerse ortofotograf√≠as de la zona que se est√° trabajando con ayuda del complemento ICGC de QGIS. Se tratar√° pues de descargar la capa, y aplicar un recorte a la capa utilizando la extensi√≥n del mdt.
* En el caso por ejemplo de las l√°minas de agua, pueden digitalizarse manualmente (o extraerse mediante clasificaci√≥n, capa de cubiertas del suelo, ...) y rasterizar la capa vectorial utilizando la extensi√≥n y resoluci√≥n de algunas de las capas raster ya existentes. Deber√° aplicarse un color a las l√°minas de agua, y guardar la capa como una imagen renderizada.
* Con el objetivo de aligerar el proceso, en el contexto de este taller, estas capas auxiliares pueden descargarse desde el **[siguiente enlace](https://drive.google.com/file/d/1fKwn9fA_OmXd5dnCQPkxt9KzJNK0JEBz/view?usp=sharing)**.
* En Blender de nuevo, dentro del panel del **Shader Editor**, hay que a√±adir dos nuevas texturas de imagen o bien sustituir alguna de las creadas inicialmente con la paleta de colores, con la imagen del ortofotomapa y la m√°scara de los lagos. De lo que se trata es de combinar ambas texturas por lo que entre estos dos nuevos nodos y el nodo relativo al shader, habr√° que incorporar un nuevo nodo Add > Color > Mix color y establecer las conexiones. 

![mix_color](/image/mix_color.png)

